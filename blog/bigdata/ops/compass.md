---
layout: default
title:  compass
description: "OPPO å¤§æ•°æ®è¯Šæ–­å¹³å° ç½—ç›˜" 
keywords: compass,ç½—ç›˜,OPPO å¤§æ•°æ®è¯Šæ–­å¹³å°,OPPO compass
author: liangrui
date: 2025-08-15
---

<div class="post-date">
  <span class="calendar-icon">ğŸ“…</span>
  <span class="date-label">å‘å¸ƒï¼š</span>
  <time datetime="2025-08-18" class="date-value">2025-08-15</time>
</div>

<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
  mermaid.initialize({ startOnLoad: true });
</script>

<div class="outline" style="background:#f6f8fa;padding:1em 1.5em 1em 1.5em;margin-bottom:2em;border-radius:8px;">
  <strong>å¤§çº²ï¼š</strong>
  <ul id="outline-list" style="margin:0;padding-left:1.2em;"></ul>
</div>


# compassè¯Šæ–­å¹³å°æ¨¡å—åˆ†æ
åº”ç”¨æ–‡æ¡£å¯ä»¥ç›´æ¥æŸ¥çœ‹ï¼š<a href="https://github.com/cubefs/compass "> compassGithub</a>
å› :è°ƒåº¦ç³»ç»Ÿæ˜¯è‡ªç ”çš„ï¼Œmysqlå¹³å°ä¸æ”¯æŒcanalé‡‡é›†,è¿™é‡Œå¯¹æºç åšäº†åˆ†æï¼Œè¿›è¡Œäº†æ•°æ®å¯¹æ¥å’Œè½¬æ¢


<div class="mermaid">
flowchart TD
  A[canal<br>åŒæ­¥è°ƒåº¦æ•°æ®è¡¨åˆ°compassè¡¨] --> B[task syncer<br>æ¶ˆè´¹mysqldataè½¬å­˜ä¸ºcompassè¡¨<br>å†™kafka: task-instance]
  B --> C[task application<br>æ¶ˆè´¹task-instance<br>æ—¥å¿—æå–app_id<br>å†™mysql: task_application<br>å‘kafka: task-application]
  C --> D[flinkæ¨¡å—<br>æ¶ˆè´¹task-application]
  B --> E[task-detect<br>æ¶ˆè´¹task-instance<br>å¼‚å¸¸æ£€æµ‹<br>å†™ES: compass-job-instance<br>å†™Redis: delayed:task]
  C --> F[task parser<br>æ¶ˆè´¹Redis: parser:processing<br>å¼•æ“å±‚å¼‚å¸¸æ£€æµ‹]
  E --> G[task portal<br>å‰ç«¯æ¥å£<br>æŠ¥å‘Šæ€»è§ˆ/è°ƒåº¦åˆ—è¡¨/ç¦»çº¿åˆ—è¡¨/è¯Šæ–­]
  F --> G
  C --> G

  subgraph DolphinScheduler
    H[flow<br>å·¥ä½œæµå®šä¹‰è¡¨]
    I[task<br>ä»»åŠ¡å®šä¹‰è¡¨]
    J[task_instance<br>ä»»åŠ¡å®ä¾‹è¡¨]
    H --> I
    I --> J
  end
</div>


## canalä½œç”¨
é€šè¿‡kafka ä¸»é¢˜ä¸º:mysqldata, è¿›è¡ŒåŒæ­¥è°ƒåº¦æ•°æ®è¡¨åˆ°compassè¡¨  
adapterä¸»è¦æ˜¯é€‚é…ä¸åŒè°ƒåº¦è¡¨æ•°æ®ï¼Œä¸»è¦é…ç½®srcDataSources:æºè°ƒåº¦çš„æ•°æ®æºï¼Œ canalAdapters:ç›®æ ‡æ•°æ®æº
å…·ä½“è¡¨è½¬æ¢è§„åˆ™åœ¨ï¼štask-canal-adapter/src/main/adapter/conf/rdb/xx.yml è¿›è¡Œé…ç½®

## task metadata
ä¸»è¦æ˜¯åŒæ­¥spark yarn çš„ä½œä¸šå…ƒæ•°æ®

## task syncer
é€šè¿‡æ¶ˆè´¹ kafkaä¸»é¢˜:mysqldataçš„è°ƒåº¦mysqlè¡¨æ•°æ®ï¼Œè½¬å­˜ä¸ºcompassè¡¨ 
å¹¶ä¸”å†™kafkaå…¥ä¿¡æ¯(xx_task_instanceè¡¨)ï¼šæ¶ˆè´¹topicï¼šmysqldata  ->  å‘é€ topic:task-instance

## task application
å°†å·¥ä½œæµå±‚ä¸å¼•æ“å±‚å…ƒæ•°æ®å…³è”  
æ¶ˆè´¹ kafkaä¸»é¢˜:task-instance, é€šè¿‡task_instance.idä»task_instanceè¡¨ä¸­æŸ¥è¯¢å‡ºå®ä¾‹ä¿¡æ¯  
é€šè¿‡è§£ææ—¥å¿—æ–‡ä»¶ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æå–å‡ºæ¥æ‰¾åˆ°å¯¹åº”çš„application_id,->rules.extractLog.name
è½¬æ¢æ•°æ®åå†™å…¥mysql -> compass.task_applicationè¡¨ä¸­ï¼Œ
å¹¶å°†TaskApplicationä¿¡æ¯å‘é€åˆ°kafka -> ä¸»é¢˜ä¸º:task-application ->flinkæ¨¡å—è¿›è¡Œæ¶ˆè´¹


## task-detect
æ¨¡å—è¿›è¡Œå·¥ä½œæµå±‚å¼‚å¸¸ä»»åŠ¡æ£€æµ‹ï¼Œä¾‹å¦‚è¿è¡Œå¤±è´¥ã€åŸºçº¿è€—æ—¶å¼‚å¸¸ç­‰  
DetectedTaské€šè¿‡æ¶ˆè´¹kafkaä¸»é¢˜ï¼štask-instanceè¿›è¡Œå¤„ç†é€»è¾‘,å–åˆ°çš„æ˜¯taskå®ä¾‹ä¿¡æ¯ï¼Œ  
å†é€šè¿‡projectName,flowName,taskName,executionTimeå»mysqlè¡¨ï¼štask_applicationæŸ¥è¯¢å‡ºappä¿¡æ¯ï¼Œ  
ç„¶åæŠŠè¯Šæ–­ç»“æœå†™å…¥  
ES -> (compass-job-instance)   
å»¶è¿Ÿçš„å®ä¾‹å¤„ç†ï¼ˆç¼ºå°‘appidï¼‰   
Redis -> ({lua}:delayed:task)    
DelayedTaskå»¶è¿Ÿä»»åŠ¡å¤„ç†ï¼Œé€šè¿‡spingBoot->CommandLineRunnerå®ç°å¯åŠ¨æ—¶è¿è¡Œ  


## task parser
è¿›è¡Œå¼•æ“å±‚å¼‚å¸¸ä»»åŠ¡æ£€æµ‹ï¼Œä¾‹å¦‚SQLå¤±è´¥ã€Shuffleå¤±è´¥ç­‰ 
ä»redisä¸­æ¶ˆè´¹->{lua}:parser:processing 

## task portal
å‰ç«¯é¡µé¢å±•ç¤ºç›¸å…³æ¥å£æ¨¡å—
æŠ¥å‘Šæ€»è§ˆ      ReportController -> /api/v1/report  
è°ƒåº¦åˆ—è¡¨å…¥å£ä¸º AppController -> /api/v1/app/list  -> æŸ¥è¯¢ESç´¢å¼•compass-task-app*   
ç¦»çº¿åˆ—è¡¨å…¥å£ä¸º JobController -> /api/v1/job/list  -> æŸ¥è¯¢ESç´¢ä¸Šcompass-job-analysis*  
ç¦»çº¿è¯Šæ–­å…¥å£  /openapi/offline/app/metadata -> redis:{lua}:log:record ->| task-parser -> RedisConsumeræ•°æ®æ¶ˆè´¹  redis:{lua}:log:record 



## dolphinSchedulerä¸»è¦è¡¨å…³ç³»
flow è¡¨ï¼ˆå·¥ä½œæµå®šä¹‰è¡¨ï¼‰  
task è¡¨ï¼ˆä»»åŠ¡å®šä¹‰è¡¨ï¼‰  
task_instance è¡¨ï¼ˆä»»åŠ¡å®ä¾‹è¡¨ï¼‰  

### ä¸‰è€…çš„å…³ç³»   
#### å±‚çº§å…³ç³»ï¼š
  ä¸€ä¸ª flowï¼ˆå·¥ä½œæµï¼‰åŒ…å«å¤šä¸ª taskï¼ˆä»»åŠ¡èŠ‚ç‚¹ï¼‰  
  å½“å·¥ä½œæµè¢«æ‰§è¡Œæ—¶ï¼Œä¼šç”Ÿæˆå·¥ä½œæµå®ä¾‹ï¼ŒåŒæ—¶ä¸ºæ¯ä¸ªä»»åŠ¡èŠ‚ç‚¹ç”Ÿæˆ task_instance  
#### æ•°æ®æµå‘ï¼š
  ç”¨æˆ·å…ˆå®šä¹‰ flowï¼ˆå·¥ä½œæµï¼‰  
  åœ¨ flow ä¸­æ·»åŠ å¤šä¸ª taskï¼ˆä»»åŠ¡èŠ‚ç‚¹ï¼‰å¹¶è®¾ç½®ä¾èµ–å…³ç³»  
  è°ƒåº¦æˆ–æ‰‹åŠ¨è§¦å‘æ—¶ï¼Œç³»ç»Ÿæ ¹æ® flow å’Œ task å®šä¹‰ç”Ÿæˆ task_instance æ‰§è¡Œ  
#### ç”Ÿå‘½å‘¨æœŸï¼š
  flow å’Œ task æ˜¯é™æ€å®šä¹‰ï¼Œä¸€èˆ¬ä¸éšæ‰§è¡Œæ”¹å˜  
  task_instance æ˜¯åŠ¨æ€ç”Ÿæˆçš„ï¼Œæ¯æ¬¡æ‰§è¡Œéƒ½ä¼šåˆ›å»ºæ–°è®°å½•  


# è‡ªå®šä¹‰è°ƒåº¦ç³»ç»Ÿè¡¨è½¬æ¢æµç¨‹
è¿™é‡Œé‡‡ç”¨äº†sparkæ¯å°æ—¶é‡‡é›†è‡ªå®šä¹‰è°ƒåº¦ç³»ç»Ÿå’Œkyuubiè¡¨ä¿¡æ¯ï¼Œæ‰¾åˆ°è°ƒåº¦->å®ä¾‹->applicationç›¸å…³ä¿¡æ¯ï¼Œæ‰¹é‡æ¸…æ´—å®Œæ•°æ®åï¼Œç»Ÿä¸€æ‰¹æ¬¡å‘é€åˆ°kafka,  
è¯Šæ–­ç³»ç»Ÿï¼ˆtask-detectï¼‰ä¼šæ¶ˆè´¹kafkaæ¶ˆæ¯ï¼Œæ¥è¿›è¡Œè‡ªåŠ¨è¯Šæ–­ï¼ŒæŠŠç»“æœå­˜å…¥ESè¿›è¡Œå±•ç¤ºï¼Œè¿™é‡Œå°±ç›´æ¥è·³è¿‡äº†task-canalå’Œtask-applicaioné¡¹ç›®å¤„ç†çš„é€»è¾‘ã€‚
 

<div class="mermaid">
graph TD
  A[æºMySQLæ•°æ®åº“] -->|1. è¯»å–æ•°æ®| B[Spark Session]
  C[Kyuubi MySQL] -->|2. è¯»å–åº”ç”¨ID| B
  B -->|3. æ•°æ®è½¬æ¢| D[ä¸´æ—¶DataFrame]
  D -->|4.1 å†™å…¥ç›®æ ‡MySQL| E[ç›®æ ‡MySQL task_instanceè¡¨]
  D -->|4.2 å†™å…¥ç›®æ ‡MySQL| F[ç›®æ ‡MySQL task_applicationè¡¨]
  D -->|5. è¿‡æ»¤æœ‰app_idçš„æ•°æ®| G[Kafkaç”Ÿäº§æ•°æ®]
  G -->|6. å‘é€æ¶ˆæ¯| H[Kafkaä¸»é¢˜ task-instance]
</div>
  

# æµç¨‹æ­¥éª¤è¯´æ˜

## æ•°æ®æºè¯»å–
###  æºMySQLï¼š
è¡¨ï¼šJOB_INST_1ï¼ˆå®ä¾‹ä¿¡æ¯ï¼‰ã€JOB_DESCï¼ˆä»»åŠ¡æè¿°ï¼‰ã€HOST_GROUP_DEFï¼ˆä¸»æœºç»„:è°ƒåº¦æ²¡æœ‰flowæ¦‚å¿µï¼Œåªæœ‰ä¾èµ–æ‹“æ‰‘å…³ç³»ï¼Œå æ—¶ç”¨è¿™ä¸ªä»£æ›¿ï¼Œåé¢å†æ¸…å…ˆè½¬æ¢ï¼‰  
 SQLæ¡ä»¶ï¼šç­›é€‰æŒ‡å®šæ—¶é—´èŒƒå›´ï¼ˆdateStartHouråˆ°å½“æ—¥23:59:59ï¼‰ä¸”ä»»åŠ¡ç±»å‹ä¸º99æˆ–96çš„è®°å½•ã€‚  

### Kyuubi MySQLï¼š
è¡¨ï¼šsqlmetadata   è·å–Sparkä»»åŠ¡çš„application_idï¼ŒæŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤å¹¶å»é‡ã€‚  

## æ•°æ®è½¬æ¢

### UDFå¤„ç†ï¼š
getTaskTypeï¼šå°†æ•°å­—ä»»åŠ¡ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚99â†’SPARKï¼‰ã€‚  
getTaskStateï¼šå°†çŠ¶æ€ç è½¬ä¸ºæ–‡æœ¬ï¼ˆå¦‚1â†’successï¼‰ã€‚  
getTriggerTypeï¼šåŒºåˆ†è§¦å‘ç±»å‹ï¼ˆscheduleæˆ–manualï¼‰ã€‚  
getExecutionTimeï¼šè§„èŒƒåŒ–æ—¶é—´æ ¼å¼ã€‚  
### å­—æ®µæ˜ å°„ï¼š
#### å­—æ®µæ˜ å°„é€»è¾‘ï¼šå‚è€ƒä»£ç æ³¨é‡Šä¸­çš„æµ·çŒ«ï¼ˆæºç³»ç»Ÿï¼‰ä¸Compassï¼ˆç›®æ ‡ç³»ç»Ÿï¼‰å­—æ®µå¯¹åº”å…³ç³»ã€‚
æºå­—æ®µï¼ˆå¦‚BUSI_GRPï¼‰â†’ç›®æ ‡å­—æ®µï¼ˆå¦‚project_nameï¼‰...ç­‰
æ•°æ®å†™å…¥ç›®æ ‡MySQL
task_instanceè¡¨ï¼š
ä½¿ç”¨ä¸´æ—¶è¡¨+ON DUPLICATE KEY UPDATEå®ç°å¹‚ç­‰å†™å…¥ï¼ˆæŒ‰idæ›´æ–°ï¼‰ã€‚
task_applicationè¡¨ï¼š
å…³è”å®ä¾‹æ•°æ®ä¸application_idï¼Œå†™å…¥ä»»åŠ¡åº”ç”¨ä¿¡æ¯ã€‚  
...
## Kafkaæ¶ˆæ¯ç”Ÿäº§
æ•°æ®è¿‡æ»¤ï¼šä»…é€‰æ‹©åŒ…å«application_idçš„å®ä¾‹è®°å½•ã€‚
### æ¶ˆæ¯æ ¼å¼ï¼š    
```
{
  "rawData": null,
  "body": {
    "id": "å®ä¾‹ID",
    "projectName": "é¡¹ç›®å",
    "flowName": "æµåç§°",
    ...
  },
  "eventType": "INSERT",
  "table": "task_instance"
}
```
### æœ€ç»ˆæ•ˆæœé¢„è§ˆ
![alt text](../../../image/ops/compass/01.png)

# è¯Šæ–­é€»è¾‘è§£æ
 é»˜è®¤è¯Šæ–­é…ç½®:compass\task-parser\src\main\resources\application.yml  

## cpuæµªè´¹è®¡ç®—
### executorè®¡ç®—
##### ä»»åŠ¡å®é™…ä½¿ç”¨çš„è®¡ç®—èµ„æºï¼ˆæ¯«ç§’ï¼‰
sparkæ‰€æœ‰çš„job æ‰§è¡Œæ—¶é—´ç›¸åŠ 
inJobComputeMillisUsed= (for-> spark.job.executorRunTime++)

##### ä»»åŠ¡å¯ç”¨çš„è®¡ç®—èµ„æºï¼ˆæ¯«ç§’ï¼‰
totalCores=executorCores*maxExecutorsï¼ˆæœ€å¤§å¹¶å‘executoræ•°ï¼‰
inJobComputeMillisAvailable = totalCores * jobTime;

##### cpuæµªè´¹æ¯”ä¾‹
 executorWastedPercentOverAll = (inJobComputeMillisAvailable - inJobComputeMillisUsed) / inJobComputeMillisAvailable * 100%
##### åˆ¤æ–­æ˜¯å¦æµªè´¹
 é˜ˆå€¼:executorThreshold=50%(é»˜è®¤)
if (cpuæµªè´¹æ¯”ä¾‹45% < é˜ˆå€¼50%)=> æ­£å¸¸
##### å¤‡æ³¨
è¿™é‡Œå¦‚æœå¯ç”¨äº†spark åŠ¨æ€åˆ†é…è®¾ç½®(spark.dynamicAllocation.enabled)ï¼Œè®¡ç®—å®Œçš„executorä¼šå…³é—­ï¼Œå®‰è¿™ç§æ–¹å¼è®¡ç®—ï¼Œä¼šæŠŠå…³é—­åçš„executorä¹Ÿä¼šç®—ä¸ºåœ¨åº”ç”¨cpuï¼Œ è¿™æ ·çš„è¯è®¡ç®—æ˜¯ä¸åˆç†çš„

### driverè®¡ç®—
- ä¸»è¦æ˜¯è®¡ç®— dirverä¸­é—´å¡é¡¿æ²¡æœ‰è®¡ç®—çš„æ¯”ä¾‹ï¼Œæ¯”å¦‚è°ƒåº¦ä¸‹ä¸€ä¸ªjobæ—¶æ²¡æœ‰èµ„æºå¯ç”¨
- appTotalTime è¡¨ç¤ºæ•´ä¸ªSparkåº”ç”¨çš„æ€»è¿è¡Œæ—¶é—´   
- jobTime è¡¨ç¤ºæ‰€æœ‰Sparkä½œä¸šå®é™…æ‰§è¡Œæ—¶é—´çš„æ€»å’Œ   
 driverComputeMillisWastedJobBased = driverTimeJobBased * totalCores  
 driverTimeJobBased = appTotalTime - jobTime ï¼ˆåº”ç”¨æ€»æ—¶é—´å‡å»ä½œä¸šæ—¶é—´ï¼‰  
 appComputeMillisAvailable = totalCores * appTotalTime ï¼ˆæ€»æ ¸å¿ƒæ•°ä¹˜ä»¥åº”ç”¨æ€»æ—¶é—´ï¼‰  
 ### driver cpuæµªè´¹æ¯”ä¾‹
 driverWastedPercentOverAll =
                ((float) driverComputeMillisWastedJobBased / appComputeMillisAvailable) * 100;
åœ¨Sparkåº”ç”¨ä¸­ï¼Œ appTotalTime å’Œ jobTime å·®è·è¾ƒå¤§çš„æƒ…å†µä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ï¼š

### appTotalTimeå’ŒjobTimeçš„å·®è·åŒºåˆ« è¯´æ˜
1. èµ„æºç­‰å¾… ï¼š     
   - å¯åŠ¨DriveråYARNæ²¡æœ‰å¯ç”¨èµ„æºæ—¶
   - ä½œä¸šæ‰§è¡Œè¿‡ç¨‹ä¸­èµ„æºè¢«æŠ¢å æˆ–é‡Šæ”¾åé‡æ–°ç”³è¯·
2. ä½œä¸šé—´éš”æœŸ ï¼š   
   - å½“ä¸€ä¸ªä½œä¸šå®Œæˆåˆ°ä¸‹ä¸€ä¸ªä½œä¸šå¼€å§‹æäº¤ä¹‹é—´çš„é—´éš”æ—¶é—´
   - è¿™ä¸ªé—´éš”æœŸä¼šè®¡å…¥ appTotalTime ä½†ä¸ä¼šè®¡å…¥ jobTime
3. å…¶ä»–æƒ…å†µ ï¼š   
   - Driveråˆå§‹åŒ–æ—¶é—´ï¼ˆåŠ è½½ä¾èµ–ã€æ³¨å†Œåº”ç”¨ç­‰ï¼‰
   - ä½œä¸šè°ƒåº¦å»¶è¿Ÿï¼ˆç‰¹åˆ«æ˜¯åœ¨åŠ¨æ€èµ„æºåˆ†é…æ¨¡å¼ä¸‹ï¼‰
   - æ•°æ®å€¾æ–œå¯¼è‡´çš„æŸäº›ä»»åŠ¡é•¿æ—¶é—´è¿è¡Œï¼Œè€Œå…¶ä»–èµ„æºå¤„äºç©ºé—²çŠ¶æ€  
   
## æˆ‘ä»¬å½“å‰çš„ç¯å¢ƒ
- æˆ‘ä»¬ç›®å‰æ²¡æœ‰å¯ç”¨ä¸¥æ ¼cpuåˆ†é…å’Œé™åˆ¶
- å¯ç”¨saprkåŠ¨æ€åˆ†é…åå’Œè®¡ç®—é€»è¾‘å†²çª 
- spark kyuubiæœºå™¨å°±æ˜¯å­˜åœ¨æµªè´¹cpuå’Œå†…å­˜å¸¸é©»è¿›ç¨‹æœºå™¨æ¥æ¢å–åŠ é€Ÿå¯åŠ¨è¿›ç¨‹ï¼Œä¼šå­˜åœ¨æµªè´¹æƒ…å†µ 

**ç»¼åˆä»¥ä¸Šè€ƒè™‘ï¼Œè¿™ä¸ªè¯Šæ–­å¯¹æˆ‘ä»¬ç›®å‰ä¸é€‚ç”¨ï¼Œå±è”½è¿™ä¸ªè¯Šæ–­é€»è¾‘ã€‚**
 executorThreshold=95  


## Taské•¿å°¾
### è¯Šæ–­æè¿°
 æ¦‚å¿µ   | äº§ç”Ÿæ–¹å¼             | æ•°é‡                      | è§„åˆ’è€…         | æ‰§è¡Œè€…
 ------ | -------------------- | ------------------------- | -------------- | ---------------
 Job    | ä¸€ä¸ª Action ç®—å­     | 1ä¸ªApplicationåŒ…å«å¤šä¸ªJob | Driver         | (æ•´ä½“)
 Stage  | æ ¹æ® å®½ä¾èµ– åˆ’åˆ†      | 1ä¸ªJobåŒ…å«å¤šä¸ªStage       | DAGScheduler   | (é˜¶æ®µ)
 Task   | ä¸ RDDåˆ†åŒº ä¸€ä¸€å¯¹åº”   | 1ä¸ªStageåŒ…å«å¤šä¸ªTask      | TaskScheduler  | Executor  

- **Taskï¼š** ä¸€ä¸ª Stage ä¼šæ ¹æ®å…¶åˆ†åŒºæ•°ï¼ˆPartitionsï¼‰è¢«æ‹†åˆ†æˆå¤šä¸ª Taskã€‚Task æ˜¯ Spark ä¸­æœ€åŸºæœ¬çš„å·¥ä½œå•å…ƒå’Œæ‰§è¡Œå•å…ƒï¼Œæ¯ä¸ª Task åœ¨ä¸€ä¸ª Executor çš„ä¸€ä¸ªæ ¸å¿ƒä¸Šå¤„ç†ä¸€ä¸ªåˆ†åŒºçš„æ•°æ®ã€‚ä¸€ä¸ª Stage çš„æ‰€æœ‰ Task æ‰§è¡Œçš„è®¡ç®—é€»è¾‘æ˜¯å®Œå…¨ä¸€æ ·çš„ï¼Œåªæ˜¯å¤„ç†çš„æ•°æ®ä¸åŒã€‚  
- stageä¸­å­˜åœ¨taskæœ€å¤§è¿è¡Œè€—æ—¶è¿œå¤§äºä¸­ä½æ•°çš„ä»»åŠ¡ä¸ºå¼‚å¸¸

### è®¡ç®—æ–¹å¼
```java
// è®¡ç®—æ¯ä¸ªtaskçš„æœ€å¤§æ‰§è¡Œæ—¶é—´ä¸ä¸­ä½æ•°çš„æ¯”å€¼
ratio = max_duration / median_duration
// taskDurationConfig.threshold default:10
å½“ ratio > threshold æ—¶ï¼ˆthresholdæ¥è‡ªé…ç½®ï¼‰ï¼Œåˆ¤å®šä¸ºé•¿å°¾å¼‚å¸¸
```
### å»ºè®®ä¼˜åŒ–
#### é¦–å…ˆç¡®è®¤æ˜¯æ•°æ®å€¾æ–œè¿˜æ˜¯è®¡ç®—å€¾æ–œ
- å¦‚æœæŸä¸ª Task çš„ Shuffle Read æ•°æ®é‡è¿œå¤§äºå…¶ä»– Taskï¼ŒåŸºæœ¬å¯ä»¥æ–­å®šæ˜¯æ•°æ®å€¾æ–œã€‚å¦‚æœå¤„ç†çš„æ•°æ®é‡å·®ä¸å¤šï¼Œä½†æ‰§è¡Œæ—¶é—´å·®åˆ«å¤§ï¼Œå¯èƒ½æ˜¯è®¡ç®—å€¾æ–œï¼ˆä¾‹å¦‚æŸä¸ªåˆ†åŒºçš„æ•°æ®å¯¼è‡´äº†æ›´å¤æ‚çš„è®¡ç®—é€»è¾‘ï¼Œå¦‚æ·±å±‚å¾ªç¯ï¼‰ã€‚
#### ä¼˜åŒ–æ–¹å‘ä¸€ï¼šåº”å¯¹æ•°æ®å€¾æ–œ (Data Skewness)
 **è¿™æ˜¯æœ€å¸¸è§çš„åŸå› ï¼Œå³æŸäº› Key å¯¹åº”çš„æ•°æ®é‡è¿œå¤§äºå…¶ä»– Keyã€‚**
 **a) é¢„å¤„ç†æ•°æ®æº**
 - **ç†æƒ³æ–¹æ¡ˆ**ï¼šå¦‚æœå¯èƒ½ï¼Œç›´æ¥ä»æ•°æ®æºç«¯è¿›è¡Œé¢„å¤„ç†ï¼Œå°†çƒ­ç‚¹æ•°æ®æ‰“æ•£ã€‚ä¾‹å¦‚åœ¨ Hive ETL é˜¶æ®µå°±å¯¹é¢‘ç¹ä½¿ç”¨çš„ Key è¿›è¡ŒåŠ ç›æˆ–æ‰“æ•£ã€‚
 **b) è¿‡æ»¤å€¾æ–œçš„Key**  
 **æ–¹æ¡ˆ**ï¼šå¦‚æœæŸäº›çƒ­ç‚¹ Key ä¸æ˜¯ä¸šåŠ¡åˆ†ææ‰€å¿…éœ€çš„ï¼ˆä¾‹å¦‚çˆ¬è™«æŠ“å–çš„å¼‚å¸¸ NULL å€¼ã€æµ‹è¯•è´¦å·çš„æ•°æ®ï¼‰ï¼Œå¯ä»¥ç›´æ¥åœ¨ä½œä¸šä¸­è¿‡æ»¤æ‰å®ƒä»¬ã€‚
 **å‘½ä»¤ç¤ºä¾‹ï¼š**
 ```scala
 // å‡è®¾ 'key' åˆ—ä¸­å­˜åœ¨ä¸€äº›æˆ‘ä»¬ä¸éœ€è¦çš„å¼‚å¸¸å¤§Key
val filteredRDD = originalRDD.filter(row => row.getAs[String]("key") != "å¼‚å¸¸Keyå€¼")  
 ```
 
- c) ä¸¤é˜¶æ®µèšåˆï¼ˆåŠ ç›/æ‰“æ•£ -> èšåˆ -> å»ç› -> æœ€ç»ˆèšåˆï¼‰  
**åœºæ™¯ï¼š**é€‚ç”¨äº reduceByKey, groupByKey, agg ç­‰èšåˆç±» Shuffle æ“ä½œã€‚  
**æ­¥éª¤ï¼š**  
**- æ‰“æ•£ï¼š**ç»™æ¯ä¸ª Key åŠ ä¸Šä¸€ä¸ªéšæœºå‰ç¼€ï¼ˆç›ï¼‰ï¼Œå°†ä¸€ä¸ªå¤§ Key æ‹†åˆ†æˆå¤šä¸ªå° Keyã€‚  

```scala
// ç¬¬ä¸€æ­¥ï¼šåŠ ç›å±€éƒ¨èšåˆ
val saltedPairRDD = originalPairRDD.map{ case (key, value) =>
  val salt = (new util.Random).nextInt(numSalts) // numSalts æ˜¯éšæœºèŒƒå›´ï¼Œä¾‹å¦‚ 10
  (s"$salt-$key", value)
}
val partialAggRDD = saltedPairRDD.reduceByKey(_ + _) // å±€éƒ¨èšåˆ
```

**- å»ç›ï¼š**å»æ‰éšæœºå‰ç¼€ï¼Œæ¢å¤åŸå§‹ Keyã€‚
```scala
// ç¬¬äºŒæ­¥ï¼šå»ç›
val removedSaltRDD = partialAggRDD.map{ case (saltedKey, value) =>
  val originalKey = saltedKey.substring(saltedKey.indexOf("-") + 1)
  (originalKey, value)
}
```

**- æœ€ç»ˆèšåˆï¼š**å¯¹æ¢å¤åçš„åŸå§‹ Key è¿›è¡Œå…¨å±€èšåˆã€‚
```scala
// ç¬¬ä¸‰æ­¥ï¼šå…¨å±€èšåˆ
val finalAggRDD = removedSaltRDD.reduceByKey(_ + _)
```
**æ•ˆæœï¼š**å°†åŸæœ¬ç”±ä¸€ä¸ª Task å¤„ç†çš„ä¸€ä¸ªå¤§ Key çš„è®¡ç®—å‹åŠ›ï¼Œåˆ†æ‘Šç»™äº†å¤šä¸ª Taskï¼Œå®Œç¾è§£å†³å€¾æ–œã€‚

 - d) ä½¿ç”¨éšæœºKeyå®ç°æ‰©å®¹join  
  - **åœºæ™¯ï¼š**é€‚ç”¨äºå¤§è¡¨ Join å€¾æ–œç»´è¡¨ï¼ˆç»´åº¦è¡¨ä¸­æœ‰çƒ­ç‚¹ Keyï¼‰ï¼Œå³ Skew Joinã€‚
  - **æ­¥éª¤ï¼š**
    - ä»å¤§è¡¨ä¸­ç­›é€‰å‡ºå¯¼è‡´å€¾æ–œçš„çƒ­ç‚¹ Key åˆ—è¡¨ã€‚
    - æ‰“æ•£å¤§è¡¨ï¼šå°†å¤§è¡¨ä¸­çƒ­ç‚¹ Key çš„æ•°æ®åŠ ä¸Šéšæœºå‰ç¼€ï¼Œä»è€Œæ‰©å®¹ã€‚
    - æ‰©å®¹ç»´è¡¨ï¼šå°†ç»´è¡¨ä¸­çƒ­ç‚¹ Key çš„æ•°æ®å¤åˆ¶å¤šä»½ï¼ˆç¬›å¡å°”ç§¯ï¼‰ï¼Œæ¯ä»½å¯¹åº”ä¸€ä¸ªéšæœºå‰ç¼€ã€‚
    - Joinï¼šå°†å¤„ç†åçš„ä¸¤ä¸ªè¡¨è¿›è¡Œ Joinï¼Œç”±äºçƒ­ç‚¹ Key è¢«æ‰©å®¹åå¯ä»¥åŒ¹é…ä¸Šï¼Œéçƒ­ç‚¹ Key æ­£å¸¸ Joinã€‚
- ä»£ç æ€è·¯å¤æ‚ï¼ŒSpark 3.2+ å·²åŸç”Ÿæ”¯æŒ SKEW JOIN ä¼˜åŒ–ï¼Œå¯é€šè¿‡ Hint å®ç°ï¼š
  ```scala
  spark.sql("""
  SELECT /*+ SKEW('table_name', 'skewed_column') */ *
  FROM table_name
  """)

  ```
***åœ¨ä½ç‰ˆæœ¬ä¸­ï¼Œé€šå¸¸éœ€è¦æ‰‹åŠ¨å®ç°ä¸Šè¿°é€»è¾‘ã€‚***

#### ä¼˜åŒ–æ–¹å‘äºŒï¼šè°ƒæ•´åˆ†åŒºä¸å¹¶è¡Œåº¦
- a) æé«˜Shuffleå¹¶è¡Œåº¦
  **æ–¹æ¡ˆï¼š**é€šè¿‡è®¾ç½® spark.sql.shuffle.partitionsï¼ˆé»˜è®¤200ï¼‰æ¥å¢åŠ  Shuffle åçš„åˆ†åŒºæ•°ã€‚  
  **åŸç†ï¼š**è®©æ•°æ®è¢«åˆ†é…åˆ°æ›´å¤šä¸ª Task ä¸­å»å¤„ç†ï¼Œå³ä½¿æœ‰æ•°æ®å€¾æ–œï¼Œæ›´å¤§çš„åˆ†åŒºæ•°ä¹Ÿå¯èƒ½è®©å€¾æ–œç¨‹åº¦ç›¸å¯¹é™ä½ã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•ä½†å¯èƒ½æœ‰æ•ˆçš„â€œç¼“å…µä¹‹è®¡â€ã€‚   
```scala
  spark.conf.set("spark.sql.shuffle.partitions", "1000") // æ ¹æ®æ•°æ®é‡è°ƒæ•´
   // æˆ–è€…åœ¨ reduceByKey ç­‰æ“ä½œä¸­ç›´æ¥æŒ‡å®šåˆ†åŒºæ•°
  rdd.reduceByKey(_ + _, 1000)
```
- b) ä½¿ç”¨è‡ªå®šä¹‰Partitioner
**æ–¹æ¡ˆï¼š**å¦‚æœä¸šåŠ¡é€»è¾‘æ¸…æ™°ï¼Œå¯ä»¥è‡ªå®šä¹‰åˆ†åŒºè§„åˆ™ï¼Œé¿å…æŸäº›åˆ†åŒºè½å…¥è¿‡å¤šæ•°æ®ã€‚
**åœºæ™¯ï¼š**ä¾‹å¦‚ï¼Œä½ æ˜ç¡®çŸ¥é“æŸäº› Key æ˜¯çƒ­ç‚¹ï¼Œå¯ä»¥ç¼–å†™è‡ªå·±çš„ Partitioner ç±»ï¼Œå°†è¿™äº› Key å¼ºåˆ¶åˆ†é…åˆ°å¤šä¸ªç‰¹å®šçš„åˆ†åŒºä¸­å»ã€‚


#### ä¼˜åŒ–æ–¹å‘ä¸‰ï¼šæ£€æŸ¥è®¡ç®—é€»è¾‘ä¸èµ„æº
- å¦‚æœä¸æ˜¯æ•°æ®é—®é¢˜ï¼Œè€Œæ˜¯è®¡ç®—é—®é¢˜ï¼š
  - **æ£€æŸ¥UDFï¼ˆç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°ï¼‰**:ä½ çš„ UDF ä¸­æ˜¯å¦å­˜åœ¨ä½æ•ˆæ“ä½œï¼ˆå¦‚é¢‘ç¹åˆ›å»ºå¯¹è±¡ã€é€’å½’è¿‡æ·±ï¼‰ï¼Ÿæ˜¯å¦åœ¨æŸäº›ç‰¹å®šæ•°æ®ä¸Šä¼šè§¦å‘ä½æ•ˆè·¯å¾„ï¼Ÿä¼˜åŒ–ä½ çš„ä»£ç é€»è¾‘ã€‚
  - **æ£€æŸ¥èµ„æºç«äº‰**:
    - **GCï¼ˆåƒåœ¾å›æ”¶ï¼‰**:é•¿å°¾ Task å¯èƒ½å› ä¸ºå¤„ç†çš„æ•°æ®é‡å¤§ï¼Œè§¦å‘äº†é¢‘ç¹çš„ Full GCã€‚åœ¨ Spark UI ä¸­æ£€æŸ¥è¯¥ Task çš„ GC æ—¶é—´ã€‚è€ƒè™‘ä½¿ç”¨ G1GC å¹¶è°ƒæ•´å †å†…å­˜å’Œ GC å‚æ•°ã€‚
    - **Executor è´Ÿè½½ä¸å‡**:å¯èƒ½æŸä¸ª Executor æ‰€åœ¨çš„ç‰©ç†æœºè´Ÿè½½æœ¬èº«å°±å¾ˆé«˜ï¼ˆCPUã€ç£ç›˜IOã€ç½‘ç»œIOè¢«å…¶ä»–è¿›ç¨‹å ç”¨ï¼‰ï¼Œå¯¼è‡´ä¸Šé¢çš„æ‰€æœ‰ Task éƒ½å˜æ…¢ã€‚éœ€è¦ä»é›†ç¾¤ç›‘æ§å±‚é¢æ’æŸ¥ã€‚

### ä¼˜åŒ–æ€»ç»“ä¸æµç¨‹
- å®šä½ï¼šä½¿ç”¨ Spark UI ç¡®å®šæ˜¯æ•°æ®å€¾æ–œè¿˜æ˜¯è®¡ç®—å€¾æ–œã€‚
- é¦–é€‰ï¼šå¦‚æœèƒ½è¿‡æ»¤æ‰å€¾æ–œKeyï¼Œè¿™æ˜¯æœ€ç›´æ¥çš„æ–¹æ³•ã€‚
- æ ¸å¿ƒæ‰‹æ®µï¼šå¯¹äºèšåˆæ“ä½œï¼Œä¼˜å…ˆè€ƒè™‘ä¸¤é˜¶æ®µèšåˆï¼ˆåŠ ç›ï¼‰ï¼›å¯¹äº Join æ“ä½œï¼Œä¼˜å…ˆçœ‹èƒ½å¦ä½¿ç”¨ Spark 3.2+ çš„ SKEW JOIN Hintã€‚
- é€šç”¨æŠ€å·§ï¼šå°è¯•å¢åŠ  Shuffle åˆ†åŒºæ•° (spark.sql.shuffle.partitions)ã€‚
- æ·±åº¦ä¼˜åŒ–ï¼šè€ƒè™‘è‡ªå®šä¹‰åˆ†åŒºå™¨æˆ–ä¼˜åŒ–UDF ä»£ç å’Œ JVM å‚æ•°ã€‚
- é•¿å°¾é—®é¢˜çš„ä¼˜åŒ–é€šå¸¸æ˜¯ä¸Šè¿°å¤šç§æ–¹æ³•ç»“åˆä½¿ç”¨ã€åå¤è¿­ä»£çš„è¿‡ç¨‹ã€‚æ ¸å¿ƒæ€æƒ³æ°¸è¿œæ˜¯ï¼šå°†é›†ä¸­åœ¨ä¸€å¤„çš„è®¡ç®—å’Œå­˜å‚¨å‹åŠ›ï¼Œå°½å¯èƒ½åœ°åˆ†æ•£åˆ°å¤šä¸ªå¹¶è¡Œå•å…ƒä¸­å»ã€‚


# åŸºçº¿æ—¶é—´å¼‚å¸¸
ç›¸å¯¹äºå†å²æ­£å¸¸ç»“æŸæ—¶é—´ï¼Œæå‰ç»“æŸæˆ–æ™šç‚¹ç»“æŸçš„ä»»åŠ¡  


## å¾…è¡¥å……æ›´å¤šçš„è¯Šæ–­é€»è¾‘åˆ†æ


# åç»­ä¼˜åŒ–
  é»˜è®¤è¯Šæ–­ä¸ç¬¦åˆå½“å‰æ•ˆæœï¼Œåç»­éœ€è¦ç»“åˆå®é™…åœºæ™¯ï¼Œç»™å‡ºä¼˜åŒ–å»ºè®®


<script>
// æ”¯æŒç‚¹å‡»äºŒçº§æ ‡é¢˜æ—¶ï¼Œæ”¶èµ·å…¶ä¸‹æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬ä¸‰çº§åŠæ›´æ·±æ ‡é¢˜å’Œå†…å®¹ï¼‰
// å¹¶è‡ªåŠ¨ç”Ÿæˆå¤§çº²ç›®å½•
document.addEventListener('DOMContentLoaded', function() {
  // æŠ˜å åŠŸèƒ½
  function getFoldContent(header) {
    let content = [];
    let el = header.nextElementSibling;
    while (el && !(el.tagName && /^H[1-6]$/.test(el.tagName) && el.tagName <= header.tagName)) {
      content.push(el);
      el = el.nextElementSibling;
    }
    return content;
  }
  document.querySelectorAll('h2, h3, h4').forEach(function(h) {
    h.classList.add('fold-title');
    let content = getFoldContent(h);
    if (content.length) {
      content.forEach(e => e.classList.add('fold-content'));
      h.addEventListener('click', function() {
        const collapsed = !h.classList.contains('collapsed');
        content.forEach(e => e.classList.toggle('collapsed', collapsed));
        h.classList.toggle('collapsed', collapsed);
      });
    }
  });
  // å¤§çº²åŠŸèƒ½
  var outline = document.getElementById('outline-list');
  if (outline) {
    document.querySelectorAll('h2').forEach(function(h, i) {
      var txt = h.textContent.replace(/^#+/, '').trim();
      // è¿‡æ»¤æ‰â€œåšå®¢è®°å½•â€æˆ–å…¶å®ƒä¸æƒ³æ˜¾ç¤ºçš„å¤§çº²é¡¹
      if (txt === 'åšå®¢è®°å½•') return;
      if (!h.id) h.id = 'outline-h2-' + i;
      var li = document.createElement('li');
      var a = document.createElement('a');
      a.href = '#' + h.id;
      a.textContent = txt;
      li.appendChild(a);
      outline.appendChild(li);
    });
  }
});
</script>


<link rel="stylesheet" href="/assets/blog.css">
<script>
function toggleBlogNav() {
  var nav = document.querySelector('.blog-nav');
  nav.classList.toggle('collapsed');
}
</script>

  <nav class="blog-nav">
    <button class="collapse-btn" onclick="toggleBlogNav()">â˜°</button>
    {% include blog_navigation.html items=site.data.blog_navigation %}
</nav>